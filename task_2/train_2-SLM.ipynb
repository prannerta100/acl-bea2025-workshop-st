{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d522ebb4-cd91-4ce8-9558-4ae4a0b856a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pip install --upgrade torch transformers accelerate bitsandbytes\n",
    "\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from transformers import AutoTokenizer, BitsAndBytesConfig, AutoModelForCausalLM, AutoModelForSequenceClassification  # Gemma3ForCausalLM\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "\n",
    "device = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b787233-28be-411e-9478-01b6ab809b04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('train.json', 'r') as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7da559bd-dad0-450f-9d42-bde3d84786d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('test.json', 'r') as file:\n",
    "    data1 = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8889730f-a14e-450b-a176-c55feb35f9a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_train = []\n",
    "for i in range(0,len(data)):\n",
    "    for j in data[i]['tutor_responses']:\n",
    "        data_train.append({\"conversation_history\": data[i]['conversation_history'],\n",
    "        \"response\": data[i]['tutor_responses'][j]['response'], \"annotation\":{\"Mistake_Location\":data[i]['tutor_responses'][j]['annotation']['Mistake_Location']}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cf8dd94-4246-43cb-a462-35c44669efc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_train1 = []\n",
    "for i in range(0,len(data1)):\n",
    "    for j in data1[i]['tutor_responses']:\n",
    "        data_train1.append({\"conversation_history\": data1[i]['conversation_history'],\n",
    "        \"response\": data1[i]['tutor_responses'][j]['response'],\n",
    "         \"annotation\":{\"Mistake_Location\":data1[i]['tutor_responses'][j]['annotation']['Mistake_Location']}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d396844-1ed5-4904-bfe4-47ee814f3898",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(data_train)\n",
    "label_map = {\n",
    "    \"No\": 0,\n",
    "    \"Yes\": 1,\n",
    "    \"To some extent\": 2  # or whatever the third label is\n",
    "}\n",
    "\n",
    "train_df[\"label\"] = train_df[\"annotation\"].apply(lambda x: label_map.get(x[\"Mistake_Location\"], -1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41cb4420-1e6e-4c9b-bd0c-2414a0960a25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(data_train1)\n",
    "test_df[\"label\"] = test_df[\"annotation\"].apply(lambda x: label_map.get(x[\"Mistake_Location\"], -1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbdfb516-9f4d-4bd0-b00f-18afe4cde303",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_history</th>\n",
       "      <th>response</th>\n",
       "      <th>annotation</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Student: 6 \\n Tutor: Excellent answer! \\n Tuto...</td>\n",
       "      <td>It sounds like you're thinking of a \"polygon,\"...</td>\n",
       "      <td>{'Mistake_Location': 'No'}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Student: 6 \\n Tutor: Excellent answer! \\n Tuto...</td>\n",
       "      <td>That's a good try! Actually, the name of the s...</td>\n",
       "      <td>{'Mistake_Location': 'Yes'}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Student: 6 \\n Tutor: Excellent answer! \\n Tuto...</td>\n",
       "      <td>Great effort! It's actually spelled \"polygon,\"...</td>\n",
       "      <td>{'Mistake_Location': 'No'}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Student: 6 \\n Tutor: Excellent answer! \\n Tuto...</td>\n",
       "      <td>That's a great try, but the correct spelling i...</td>\n",
       "      <td>{'Mistake_Location': 'No'}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Student: 6 \\n Tutor: Excellent answer! \\n Tuto...</td>\n",
       "      <td>That is a good try.</td>\n",
       "      <td>{'Mistake_Location': 'No'}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>Tutor: Hi, could you please provide a step-by-...</td>\n",
       "      <td>I appreciate your reasoning, but let's take a ...</td>\n",
       "      <td>{'Mistake_Location': 'Yes'}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>Tutor: Hi, could you please provide a step-by-...</td>\n",
       "      <td>That's true, but if there are 50 this week, ho...</td>\n",
       "      <td>{'Mistake_Location': 'No'}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>Tutor: Hi, could you please provide a step-by-...</td>\n",
       "      <td>That's a great idea to try to figure out the n...</td>\n",
       "      <td>{'Mistake_Location': 'Yes'}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>Tutor: Hi, could you please provide a step-by-...</td>\n",
       "      <td>I see what you're trying to do, but the questi...</td>\n",
       "      <td>{'Mistake_Location': 'Yes'}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>Tutor: Hi, could you please provide a step-by-...</td>\n",
       "      <td>I understand why you might think that, but the...</td>\n",
       "      <td>{'Mistake_Location': 'No'}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>409 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  conversation_history  \\\n",
       "0    Student: 6 \\n Tutor: Excellent answer! \\n Tuto...   \n",
       "1    Student: 6 \\n Tutor: Excellent answer! \\n Tuto...   \n",
       "2    Student: 6 \\n Tutor: Excellent answer! \\n Tuto...   \n",
       "3    Student: 6 \\n Tutor: Excellent answer! \\n Tuto...   \n",
       "4    Student: 6 \\n Tutor: Excellent answer! \\n Tuto...   \n",
       "..                                                 ...   \n",
       "404  Tutor: Hi, could you please provide a step-by-...   \n",
       "405  Tutor: Hi, could you please provide a step-by-...   \n",
       "406  Tutor: Hi, could you please provide a step-by-...   \n",
       "407  Tutor: Hi, could you please provide a step-by-...   \n",
       "408  Tutor: Hi, could you please provide a step-by-...   \n",
       "\n",
       "                                              response  \\\n",
       "0    It sounds like you're thinking of a \"polygon,\"...   \n",
       "1    That's a good try! Actually, the name of the s...   \n",
       "2    Great effort! It's actually spelled \"polygon,\"...   \n",
       "3    That's a great try, but the correct spelling i...   \n",
       "4                                  That is a good try.   \n",
       "..                                                 ...   \n",
       "404  I appreciate your reasoning, but let's take a ...   \n",
       "405  That's true, but if there are 50 this week, ho...   \n",
       "406  That's a great idea to try to figure out the n...   \n",
       "407  I see what you're trying to do, but the questi...   \n",
       "408  I understand why you might think that, but the...   \n",
       "\n",
       "                      annotation  label  \n",
       "0     {'Mistake_Location': 'No'}      0  \n",
       "1    {'Mistake_Location': 'Yes'}      1  \n",
       "2     {'Mistake_Location': 'No'}      0  \n",
       "3     {'Mistake_Location': 'No'}      0  \n",
       "4     {'Mistake_Location': 'No'}      0  \n",
       "..                           ...    ...  \n",
       "404  {'Mistake_Location': 'Yes'}      1  \n",
       "405   {'Mistake_Location': 'No'}      0  \n",
       "406  {'Mistake_Location': 'Yes'}      1  \n",
       "407  {'Mistake_Location': 'Yes'}      1  \n",
       "408   {'Mistake_Location': 'No'}      0  \n",
       "\n",
       "[409 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81e17d51-612a-4598-8bbb-19d5ac0f2522",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2104, 4)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.concat([train_df, test_df], axis=0).reset_index(drop=True)\n",
    "train_df, test_df = train_test_split(train_df, test_size=0.15, random_state=42)\n",
    "\n",
    "# df1 = train_df[train_df[\"actionability\"] == \"Yes\"].sample(n=450)\n",
    "# df2 = train_df[train_df[\"actionability\"] == \"No\"].sample(n=400)\n",
    "# df3 = train_df[train_df[\"actionability\"] == \"To some extent\"].sample(n=328)\n",
    "# train_df = pd.concat([df1, df2, df3], axis=0)\n",
    "\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "629e99ac-f99f-4e73-824e-524f37045fd7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1303\n",
       "0     611\n",
       "2     190\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8437100f-f547-4aca-9249-0bc9daaf52bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_df.conversation[9].split(\"\\n\")[-1]\n",
    "# test_df[\"response\"] = test_df[\"conversation\"].apply(lambda x: x.split(\"\\nTutor: \")[-1])\n",
    "# train_df[\"response\"] = train_df[\"conversation\"].apply(lambda x: x.split(\"\\nTutor: \")[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51c18fd8-a807-4b47-8389-742d2a2f4b8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def combine_inputs(row):\n",
    "    return f\"CONVERSATION: {row['conversation_history']} RESPONSE: {row['response']}\"\n",
    "\n",
    "train_df[\"text\"] = train_df.apply(combine_inputs, axis=1)\n",
    "test_df[\"text\"] = test_df.apply(combine_inputs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "071de810-0e0b-4f96-8ac2-c5fc97fc6d11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ConvoData(Dataset):\n",
    "    def __init__(self, df, tokenizer):\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.tokenized_data = []\n",
    "\n",
    "        kwargs = {\n",
    "            \"max_length\": 768,\n",
    "            \"padding\": \"max_length\",\n",
    "            \"truncation\": True,\n",
    "            \"return_attention_mask\": True,\n",
    "            \"return_tensors\": \"pt\"\n",
    "        }\n",
    "\n",
    "        for idx in range(len(df)):\n",
    "            label = df.iloc[idx][\"label\"]\n",
    "            resp = df.iloc[idx][\"text\"]\n",
    "            tokens = tokenizer(resp, **kwargs)\n",
    "            self.tokenized_data.append((tokens, label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.tokenized_data[item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec34315f-b5f9-44b3-9f8d-51b8cb52950a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cc5b3ba24f64ebab1bb821feb239fc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Phi3ForSequenceClassification were not initialized from the model checkpoint at microsoft/Phi-4-mini-instruct and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_id = \"microsoft/Phi-4-mini-instruct\"\n",
    "# model_id = \"unsloth/Meta-Llama-3.1-8B-Instruct\"\n",
    "# model_id = \"unsloth/Qwen2.5-3B-Instruct\"\n",
    "# model_id = \"unsloth/phi-4-bnb-4bit\"\n",
    "# model_id = \"Qwen/Qwen2.5-7B-Instruct\"\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(load_in_16bit=True)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_id,\n",
    "    num_labels=3,\n",
    "    quantization_config=quantization_config,\n",
    "    device_map=\"cuda:3\",\n",
    "    torch_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "model.config.pad_token_id = model.config.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef36fce8-67c1-4049-b015-c12984900892",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# ls = train_df[\"response\"].apply(lambda x: len(tokenizer(x).input_ids))\n",
    "# plt.plot(range(len(ls)), ls)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de735140-a334-4034-bfcb-8ba99fa9a115",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "356f02ef-ee4b-40a5-ab2c-537b4e7d3f36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL_ABB = \"phi4_mini_it\"\n",
    "LOG_PATH = \"logs/training_log_phi4_less_data.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a54750b4-2d30-4023-915e-c27de0beb97c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "# labels = np.array(train_df.label)\n",
    "# class_sample_counts = np.bincount(labels)  # count per class\n",
    "# class_weights = 1. / class_sample_counts\n",
    "\n",
    "# sample_weights = class_weights[labels]  # gives weight for each sample\n",
    "\n",
    "# sampler = WeightedRandomSampler(\n",
    "#     weights=torch.tensor(sample_weights, dtype=torch.double),\n",
    "#     num_samples=len(sample_weights),  # total samples per epoch\n",
    "#     replacement=True\n",
    "# )\n",
    "\n",
    "train_data = ConvoData(train_df, tokenizer)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=4,\n",
    "    # sampler=sampler\n",
    ")\n",
    "\n",
    "# tokenizer.batch_decode(train_data[1][0][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d2c5928-987c-4447-be04-cc95425b1a80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def eval_on_test(epoch, df, test_flag, write=True):\n",
    "    model.eval()\n",
    "\n",
    "    test_data = ConvoData(df, tokenizer)\n",
    "\n",
    "    test_dataloader = DataLoader(\n",
    "        test_data,\n",
    "        batch_size=2,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    true = []\n",
    "    preds = []\n",
    "\n",
    "    for batch_id, batch in enumerate(test_dataloader):\n",
    "        input_ids = batch[0]['input_ids'].squeeze(dim=1).to(device)\n",
    "        attention_mask = batch[0]['attention_mask'].squeeze(dim=1).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                output_hidden_states=False\n",
    "            )\n",
    "            out = F.log_softmax(out.logits, dim=-1)\n",
    "\n",
    "            true += batch[1].tolist()\n",
    "            preds += out.argmax(dim=-1).tolist()\n",
    "\n",
    "    if test_flag:\n",
    "        text = \"On test Set:\"\n",
    "    else:\n",
    "        text = \"On sampled train Set:\"\n",
    "\n",
    "    acc = sum([i == j for i, j in zip(preds, true)]) / len(test_data)\n",
    "    f1 = f1_score(true, preds, average='macro')\n",
    "    print(text)\n",
    "    print(\"Accuracy:\", acc)\n",
    "    print(\"F1 score:\", f1, \"\\n\")\n",
    "    \n",
    "    if write:\n",
    "        with open(LOG_PATH, \"a\") as file:\n",
    "            w = f\"\"\"\n",
    "            {text}\n",
    "            Epoch: {epoch + 1}\n",
    "            Accuracy: {acc},\n",
    "            F1 score: {f1}\\n\n",
    "            \"\"\"\n",
    "            file.write(w)\n",
    "\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "04bde8cf-cf61-44c5-bfb5-0c52fee89b85",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6953125\n",
      "0.29296875\n",
      "0.94921875\n",
      "0.2734375\n",
      "1.0\n",
      "0.96875\n",
      "0.72265625\n",
      "1.609375\n",
      "1.546875\n",
      "0.443359375\n",
      "0.5234375\n",
      "0.7421875\n",
      "0.5234375\n",
      "1.4921875\n",
      "1.03125\n",
      "0.466796875\n",
      "0.984375\n",
      "0.6171875\n",
      "0.7890625\n",
      "0.6328125\n",
      "\n",
      "Epoch 1\n",
      "Average Training Loss: 0.8451\n",
      "On sampled train Set:\n",
      "Accuracy: 0.6975\n",
      "F1 score: 0.4554284676833696 \n",
      "\n",
      "On test Set:\n",
      "Accuracy: 0.6478494623655914\n",
      "F1 score: 0.40561237093028996 \n",
      "\n",
      "0.52734375\n",
      "0.796875\n",
      "0.37890625\n",
      "0.7890625\n",
      "1.1796875\n",
      "0.62109375\n",
      "1.59375\n",
      "1.4921875\n",
      "0.5078125\n",
      "0.423828125\n",
      "0.6796875\n",
      "0.435546875\n",
      "1.46875\n",
      "0.91796875\n",
      "0.4375\n",
      "0.40234375\n",
      "0.953125\n",
      "0.50390625\n",
      "0.765625\n",
      "0.62109375\n",
      "\n",
      "Epoch 2\n",
      "Average Training Loss: 0.7786\n",
      "On sampled train Set:\n",
      "Accuracy: 0.745\n",
      "F1 score: 0.48176507957925035 \n",
      "\n",
      "On test Set:\n",
      "Accuracy: 0.6532258064516129\n",
      "F1 score: 0.41614477237197406 \n",
      "\n",
      "0.42578125\n",
      "0.26171875\n",
      "0.703125\n",
      "0.41796875\n",
      "0.73046875\n",
      "1.171875\n",
      "1.5\n",
      "1.4375\n",
      "0.50390625\n",
      "0.375\n",
      "0.51171875\n",
      "0.41796875\n",
      "1.328125\n",
      "0.9609375\n",
      "0.38671875\n",
      "0.609375\n",
      "1.015625\n",
      "0.578125\n",
      "0.65234375\n",
      "0.59765625\n",
      "\n",
      "Epoch 3\n",
      "Average Training Loss: 0.7480\n",
      "On sampled train Set:\n",
      "Accuracy: 0.7075\n",
      "F1 score: 0.4631479631479632 \n",
      "\n",
      "On test Set:\n",
      "Accuracy: 0.6666666666666666\n",
      "F1 score: 0.4165079365079365 \n",
      "\n",
      "0.482421875\n",
      "0.3046875\n",
      "0.76171875\n",
      "0.46484375\n",
      "0.6796875\n",
      "1.03125\n",
      "0.6875\n",
      "1.46875\n",
      "1.3828125\n",
      "0.49609375\n",
      "0.330078125\n",
      "0.55078125\n",
      "0.4921875\n",
      "1.328125\n",
      "0.8671875\n",
      "0.400390625\n",
      "0.6171875\n",
      "0.99609375\n",
      "0.57421875\n",
      "0.64453125\n",
      "0.5703125\n",
      "\n",
      "Epoch 4\n",
      "Average Training Loss: 0.7324\n",
      "On sampled train Set:\n",
      "Accuracy: 0.7125\n",
      "F1 score: 0.4682908822443706 \n",
      "\n",
      "On test Set:\n",
      "Accuracy: 0.6612903225806451\n",
      "F1 score: 0.41171075837742505 \n",
      "\n",
      "0.4296875\n",
      "0.3203125\n",
      "0.83984375\n",
      "0.455078125\n",
      "0.671875\n",
      "1.015625\n",
      "0.68359375\n",
      "1.4375\n",
      "1.3203125\n",
      "0.4609375\n",
      "0.240234375\n",
      "0.474609375\n",
      "0.435546875\n",
      "1.40625\n",
      "0.84765625\n",
      "0.39453125\n",
      "0.6015625\n",
      "1.0078125\n",
      "0.5703125\n",
      "0.6015625\n",
      "0.54296875\n",
      "\n",
      "Epoch 5\n",
      "Average Training Loss: 0.7085\n",
      "On sampled train Set:\n",
      "Accuracy: 0.7325\n",
      "F1 score: 0.4878174629038215 \n",
      "\n",
      "On test Set:\n",
      "Accuracy: 0.6801075268817204\n",
      "F1 score: 0.4230769230769231 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "accumulation_steps = 1\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "scheduler = ExponentialLR(optimizer, gamma=0.9)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch_id, batch in enumerate(train_dataloader):\n",
    "        input_ids = batch[0]['input_ids'].squeeze(dim=1).to(device)\n",
    "        attention_mask = batch[0]['attention_mask'].squeeze(dim=1).to(device)\n",
    "\n",
    "        out = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            output_hidden_states=False\n",
    "        )\n",
    "\n",
    "        loss = loss_fn(out.logits, batch[1].to(device))\n",
    "        loss.backward()\n",
    "\n",
    "        if (batch_id + 1) % accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        if (batch_id + 1) % 25 == 0:\n",
    "            print(loss.item())\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    # If the number of batches isn't divisible by accumulation_steps,\n",
    "    # do one final step after the loop ends\n",
    "    if (batch_id + 1) % accumulation_steps != 0:\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "    print(f\"\\nEpoch {epoch + 1}\")\n",
    "    print(f\"Average Training Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    eval_on_test(epoch, train_df.sample(n=400), test_flag=False)\n",
    "    f1 = eval_on_test(epoch, test_df, test_flag=True)\n",
    "\n",
    "    if f1 >= 0.2:\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "        }\n",
    "        torch.save(checkpoint, f\"epoch_{epoch + 1}_{MODEL_ABB}_{f1}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5079def-989c-4304-8884-ba807711087b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8525\n",
      "F1 score: 0.8449993807406342\n"
     ]
    }
   ],
   "source": [
    "# model.eval()\n",
    "\n",
    "# test_data = ConvoData(train_df.sample(n=400), tokenizer)\n",
    "\n",
    "# test_dataloader = DataLoader(\n",
    "#     test_data,\n",
    "#     batch_size=4,\n",
    "#     shuffle=False\n",
    "# )\n",
    "\n",
    "# true = []\n",
    "# preds = []\n",
    "\n",
    "# for batch_id, batch in enumerate(test_dataloader):\n",
    "#     input_ids = batch[0]['input_ids'].squeeze(dim=1).to(device)\n",
    "#     attention_mask = batch[0]['attention_mask'].squeeze(dim=1).to(device)\n",
    "\n",
    "#     out = model(\n",
    "#         input_ids=input_ids,\n",
    "#         attention_mask=attention_mask,\n",
    "#         output_hidden_states=False\n",
    "#     )\n",
    "#     out = F.log_softmax(out.logits, dim=-1)\n",
    "\n",
    "#     true += batch[1].tolist()\n",
    "#     preds += out.argmax(dim=-1).tolist()\n",
    "\n",
    "# acc = sum([i == j for i, j in zip(preds, true)]) / len(test_data)\n",
    "# f1 = f1_score(true, preds, average='macro')\n",
    "# print(\"Accuracy:\", acc)\n",
    "# print(\"F1 score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8283303b-ea86-466f-b709-10684190ffcc",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a4d75110-8dfa-4cad-82a8-bac8a896bfab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mphi4/epoch_4_phi4_mini_it_5777.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(checkpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_state_dict\u001b[39m\u001b[38;5;124m'\u001b[39m], strict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOk\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/serialization.py:1462\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights_only:\n\u001b[1;32m   1461\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1462\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1463\u001b[0m \u001b[43m            \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1464\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1465\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_weights_only_unpickler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1466\u001b[0m \u001b[43m            \u001b[49m\u001b[43moverall_storage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverall_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1467\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1468\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1469\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1470\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/serialization.py:1964\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1962\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m _serialization_tls\n\u001b[1;32m   1963\u001b[0m _serialization_tls\u001b[38;5;241m.\u001b[39mmap_location \u001b[38;5;241m=\u001b[39m map_location\n\u001b[0;32m-> 1964\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1965\u001b[0m _serialization_tls\u001b[38;5;241m.\u001b[39mmap_location \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1967\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/_weights_only_unpickler.py:512\u001b[0m, in \u001b[0;36mUnpickler.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    504\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    505\u001b[0m         \u001b[38;5;28mtype\u001b[39m(pid) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m\n\u001b[1;32m    506\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(pid) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mserialization\u001b[38;5;241m.\u001b[39m_maybe_decode_ascii(pid[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    508\u001b[0m     ):\n\u001b[1;32m    509\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m UnpicklingError(\n\u001b[1;32m    510\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly persistent_load of storage is allowed, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpid[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    511\u001b[0m         )\n\u001b[0;32m--> 512\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpersistent_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpid\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    513\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m [BINGET[\u001b[38;5;241m0\u001b[39m], LONG_BINGET[\u001b[38;5;241m0\u001b[39m]]:\n\u001b[1;32m    514\u001b[0m     idx \u001b[38;5;241m=\u001b[39m (read(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m key[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m BINGET[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m unpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<I\u001b[39m\u001b[38;5;124m\"\u001b[39m, read(\u001b[38;5;241m4\u001b[39m)))[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/serialization.py:1928\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1926\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1927\u001b[0m     nbytes \u001b[38;5;241m=\u001b[39m numel \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_element_size(dtype)\n\u001b[0;32m-> 1928\u001b[0m     typed_storage \u001b[38;5;241m=\u001b[39m \u001b[43mload_tensor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1929\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_maybe_decode_ascii\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1930\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1932\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m typed_storage\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/serialization.py:1900\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1895\u001b[0m         storage\u001b[38;5;241m.\u001b[39mbyteswap(dtype)\n\u001b[1;32m   1897\u001b[0m \u001b[38;5;66;03m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[1;32m   1898\u001b[0m \u001b[38;5;66;03m# stop wrapping with TypedStorage\u001b[39;00m\n\u001b[1;32m   1899\u001b[0m typed_storage \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstorage\u001b[38;5;241m.\u001b[39mTypedStorage(\n\u001b[0;32m-> 1900\u001b[0m     wrap_storage\u001b[38;5;241m=\u001b[39m\u001b[43mrestore_location\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   1901\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m   1902\u001b[0m     _internal\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   1903\u001b[0m )\n\u001b[1;32m   1905\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typed_storage\u001b[38;5;241m.\u001b[39m_data_ptr() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1906\u001b[0m     loaded_storages[key] \u001b[38;5;241m=\u001b[39m typed_storage\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/serialization.py:693\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    674\u001b[0m \u001b[38;5;124;03mRestores `storage` using a deserializer function registered for the `location`.\u001b[39;00m\n\u001b[1;32m    675\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;124;03m       all matching ones return `None`.\u001b[39;00m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    692\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, _, fn \u001b[38;5;129;01min\u001b[39;00m _package_registry:\n\u001b[0;32m--> 693\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    694\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    695\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/serialization.py:632\u001b[0m, in \u001b[0;36m_deserialize\u001b[0;34m(backend_name, obj, location)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m location\u001b[38;5;241m.\u001b[39mstartswith(backend_name):\n\u001b[1;32m    631\u001b[0m     device \u001b[38;5;241m=\u001b[39m _validate_device(location, backend_name)\n\u001b[0;32m--> 632\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/storage.py:292\u001b[0m, in \u001b[0;36m_StorageBase.to\u001b[0;34m(self, device, non_blocking)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(device, torch\u001b[38;5;241m.\u001b[39mdevice):\n\u001b[1;32m    291\u001b[0m     device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(device)\n\u001b[0;32m--> 292\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_to\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/_utils.py:85\u001b[0m, in \u001b[0;36m_to\u001b[0;34m(self, device, non_blocking)\u001b[0m\n\u001b[1;32m     81\u001b[0m device_module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(torch, device\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m     83\u001b[0m     device_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     84\u001b[0m ), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;241m.\u001b[39mtype\u001b[38;5;241m.\u001b[39mupper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m device module is not loaded\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 85\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m device_module\u001b[38;5;241m.\u001b[39mdevice(device):\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_sparse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(device_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     87\u001b[0m         new_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(device_module\u001b[38;5;241m.\u001b[39msparse, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/cuda/__init__.py:442\u001b[0m, in \u001b[0;36mdevice.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 442\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprev_idx \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_exchange_device\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load(f\"phi4/epoch_4_phi4_mini_it_5777.pth\")\n",
    "\n",
    "model.load_state_dict(checkpoint['model_state_dict'], strict=False)\n",
    "\n",
    "print(\"Ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f99bccd2-e8a0-4b04-b0a4-2ddb662d1e07",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation</th>\n",
       "      <th>actionability</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1737</th>\n",
       "      <td>Tutor: Hi, could you please provide a step-by-...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>Tutor: Hi, could you please provide a step-by-...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1565</th>\n",
       "      <td>Tutor: We need to subtract total windows from ...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>Tutor: Hi, could you please provide a step-by-...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Tutor: Hi, could you please provide a step-by-...</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1351</th>\n",
       "      <td>Tutor: Hi, could you please provide a step-by-...</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1316</th>\n",
       "      <td>Tutor: Hi, could you please provide a step-by-...</td>\n",
       "      <td>To some extent</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>Tutor: Go ahead and solve this question. \\n St...</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1083</th>\n",
       "      <td>Tutor: We can compare the ratios more easily i...</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068</th>\n",
       "      <td>Tutor: Hi, could you please provide a step-by-...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>248 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           conversation   actionability  label\n",
       "1737  Tutor: Hi, could you please provide a step-by-...             Yes      0\n",
       "246   Tutor: Hi, could you please provide a step-by-...             Yes      0\n",
       "1565  Tutor: We need to subtract total windows from ...             Yes      0\n",
       "432   Tutor: Hi, could you please provide a step-by-...             Yes      0\n",
       "56    Tutor: Hi, could you please provide a step-by-...              No      1\n",
       "...                                                 ...             ...    ...\n",
       "1351  Tutor: Hi, could you please provide a step-by-...              No      1\n",
       "1316  Tutor: Hi, could you please provide a step-by-...  To some extent      2\n",
       "888   Tutor: Go ahead and solve this question. \\n St...              No      1\n",
       "1083  Tutor: We can compare the ratios more easily i...              No      1\n",
       "1068  Tutor: Hi, could you please provide a step-by-...             Yes      0\n",
       "\n",
       "[248 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6bf3babe-0839-4f99-b137-c7eb7aa5df8e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "F1 score: 0.0\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "test_data = ConvoData(test_df, tokenizer)\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_data,\n",
    "    batch_size=4,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "true = []\n",
    "preds = []\n",
    "\n",
    "for batch_id, batch in enumerate(test_dataloader):\n",
    "    input_ids = batch[0]['input_ids'].squeeze(dim=1).to(device)\n",
    "    attention_mask = batch[0]['attention_mask'].squeeze(dim=1).to(device)\n",
    "\n",
    "    out = model(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        output_hidden_states=False\n",
    "    )\n",
    "    out = F.log_softmax(out.logits, dim=-1)\n",
    "\n",
    "    true += batch[1].tolist()\n",
    "    preds += out.argmax(dim=-1).tolist()\n",
    "\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print(sum([i == j for i, j in zip(preds, true)]) / len(test_data))\n",
    "print(\"F1 score:\", f1_score(true, preds, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86b8e884-896e-48ce-9038-b3758a7a724f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch_1_275_phi4_intrm_2.pth    :  0.65463\n",
    "# epoch_1_275_phi4_intrm.pth      :  0.6727\n",
    "# epoch_1_phi4_4b_ns_all.pth      :  0.6815\n",
    "# epoch_2_phi4_intrm_2_174.pth    :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94ad8ce-c519-4aff-897e-9bb91430df82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f57d8bd-91f3-4551-b152-d748e0dad8c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03f5511-f481-4713-bb3a-69ca84976347",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b2b1b071-ddfa-49f4-b9cc-95cf5c3803de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1190\n",
       "1     710\n",
       "2     328\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca8e0df-c2f4-452e-a6de-a73523f19b96",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Subs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "730ca479-020c-4c76-a429-fb66597ff253",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# quantization_config = BitsAndBytesConfig(load_in_16bit=True)\n",
    "\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(\n",
    "#     \"./ckpt_epoch20_qwen25\",\n",
    "#     num_labels=3,\n",
    "#     quantization_config=quantization_config,\n",
    "#     device_map=\"cuda:3\",\n",
    "#     torch_dtype=torch.bfloat16\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0078d4cd-7d23-430f-a883-c73882a0eaad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "test_df = pd.read_csv(\"real_test.csv\")\n",
    "test_df[\"label\"] = -1\n",
    "\n",
    "test_data = ConvoData(test_df, tokenizer)\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_data,\n",
    "    batch_size=4,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "true = []\n",
    "preds = []\n",
    "\n",
    "for batch_id, batch in enumerate(test_dataloader):\n",
    "    input_ids = batch[0]['input_ids'].squeeze(dim=1).to(device)\n",
    "    attention_mask = batch[0]['attention_mask'].squeeze(dim=1).to(device)\n",
    "\n",
    "    out = model(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        output_hidden_states=False\n",
    "    )\n",
    "    out = F.log_softmax(out.logits, dim=-1)\n",
    "\n",
    "    # true += batch[1].tolist()\n",
    "    preds += out.argmax(dim=-1).tolist()\n",
    "\n",
    "test_df[\"preds\"] = preds\n",
    "test_df.to_csv(\"sub_bea.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8843c0d3-779c-4726-8267-922a09ebc268",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 717, 1: 425, 2: 405})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "Counter(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2cfb828f-83e5-4339-b6ed-8f483e0b6514",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26179702650290887"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "405 / 1547"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "567a15fe-4089-44ea-8d60-14555144302e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1547"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "220bf383-ccd4-407b-9d5f-bfa43db581b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "sub = pd.read_csv(\"sub_bea.csv\")\n",
    "\n",
    "sub_grouped = sub.groupby(by=[\"conversation_id\", \"conversation_history\"]).agg(list)\n",
    "\n",
    "label_dict = {\n",
    "    \"Yes\": 0,\n",
    "    \"No\": 1,\n",
    "    \"To some extent\": 2\n",
    "}\n",
    "\n",
    "label_dict_rev = {v: k for k, v in label_dict.items()}\n",
    "\n",
    "final = []\n",
    "\n",
    "for row in sub_grouped.iterrows():\n",
    "    d = {}\n",
    "    id = row[0][0]\n",
    "    hist = row[0][1]\n",
    "    resp = {}\n",
    "    for t in range(len(row[1][\"tutor\"])):\n",
    "        resp[row[1][\"tutor\"][t]] = {\n",
    "            \"response\": row[1][\"response\"][t],\n",
    "            \"annotation\": {\n",
    "                \"Actionability\": label_dict_rev[row[1][\"preds\"][t]]\n",
    "            }\n",
    "        }\n",
    "\n",
    "    d[\"conversation_id\"] = id\n",
    "    d[\"conversation_history\"] = hist\n",
    "    d[\"tutor_responses\"] = resp\n",
    "\n",
    "    final.append(d)\n",
    "\n",
    "json.dump(final, open(\"phi_4_ns_all.json\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e81d5adb-73b1-4c22-8664-98b1c1c55344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "259"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f814484-47b2-4039-b0aa-e9d410caa312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "386"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce95099e-0e19-4cde-8d73-27d8012a30dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54931150-faed-4a65-8872-1b6cbc0bd8e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fa2807-487f-462b-ab33-02e489e514f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900af8b4-92cc-4a6d-9bbc-2434c46d2f3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57020691-9b92-43dc-b61c-8d9d45e0526e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78395a9-14d4-487d-bb16-8f1511c07c78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2449103-427c-4f3f-bda7-409d855a4671",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92f4b427-c083-43f0-9c68-9aa7263e2ced",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "model.eval()\n",
    "\n",
    "test_df = pd.read_csv(\"test_sanity_bea.csv\")\n",
    "\n",
    "test_data = ConvoData(test_df, tokenizer)\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_data,\n",
    "    batch_size=4,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "true = []\n",
    "preds = []\n",
    "\n",
    "for batch_id, batch in enumerate(test_dataloader):\n",
    "    input_ids = batch[0]['input_ids'].squeeze(dim=1).to(device)\n",
    "    attention_mask = batch[0]['attention_mask'].squeeze(dim=1).to(device)\n",
    "\n",
    "    out = model(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        output_hidden_states=False\n",
    "    )\n",
    "    out = F.log_softmax(out.logits, dim=-1)\n",
    "\n",
    "    # true += batch[1].tolist()\n",
    "    preds += out.argmax(dim=-1).tolist()\n",
    "\n",
    "test_df[\"preds\"] = preds\n",
    "\n",
    "sub_grouped = test_df.groupby(by=[\"conversation_id\", \"conversation_history\"]).agg(list)\n",
    "\n",
    "label_dict = {\n",
    "    \"Yes\": 0,\n",
    "    \"No\": 1,\n",
    "    \"To some extent\": 2\n",
    "}\n",
    "\n",
    "label_dict_rev = {v: k for k, v in label_dict.items()}\n",
    "\n",
    "final = []\n",
    "\n",
    "for row in sub_grouped.iterrows():\n",
    "    d = {}\n",
    "    id = row[0][0]\n",
    "    hist = row[0][1]\n",
    "    resp = {}\n",
    "    for t in range(len(row[1][\"tutor\"])):\n",
    "        resp[row[1][\"tutor\"][t]] = {\n",
    "            \"response\": row[1][\"response\"][t],\n",
    "            \"annotation\": {\n",
    "                \"Actionability\": label_dict_rev[row[1][\"preds\"][t]]\n",
    "            }\n",
    "        }\n",
    "\n",
    "    d[\"conversation_id\"] = id\n",
    "    d[\"conversation_history\"] = hist\n",
    "    d[\"tutor_responses\"] = resp\n",
    "\n",
    "    final.append(d)\n",
    "\n",
    "json.dump(final, open(\"test_sanity.json\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "531858ee-37a3-432d-acfb-1a3c562e2d59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tutor       [Llama31405B, Phi3, Expert, Gemini, GPT4, Llam...\n",
       "response    [It looks like everything makes sense up until...\n",
       "preds                                [2, 0, 0, 1, 0, 0, 0, 0]\n",
       "Name: (1490-cc82c3fe-3e61-4189-acda-2138219edee1, Tutor: Hi, could you please provide a step-by-step solution for the question below? The question is: Kenny is selling his Pokemon cards to buy a ticket to an amusement park, which costs $100. He has a collection of cards and plans to sell them for $1.5 each. He keeps 1/3 of them and gets to go to the amusement park with $50 in spending cash. How many cards did he start with? \\n Student: Let x be the total number of cards Kenny started with.\\nHe kept 1/3 of them, so he sold 2/3 of them, which is 2/3x.\\nHe sold them for $1.5 each, so he earned 1.5(2/3x) = 3x/2 dollars.\\nHe wants to end up with $50 spending cash, so he needs to earn $100 + $50 = $150 in total.\\nTherefore, 3x/2 = $150.\\nSolving for x, we get x = 100.\\nKenny started with 100 cards.\\n 100 \\n Tutor: can you talk me through your solution? \\n Student: Sure. I started by letting x be the total number of cards Kenny started with. Then I said he kept 1/3 of them so he sold 2/3 of them which is 2/3x. He sold them for $1.5 each so he earned 1.5(2/3x) = 3x/2 dollars. He wanted to end up with $50 spending cash so he needed to earn $100 + $50 = $150 in total. Therefore 3x/2 = $150. I then solved for x and got x = 100 which means Kenny started with 100 cards.), dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_grouped.iloc[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8154ed8-ab5e-4984-9c54-cdd361eafbd0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>conversation_history</th>\n",
       "      <th>tutor</th>\n",
       "      <th>response</th>\n",
       "      <th>preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>296362576</td>\n",
       "      <td>Student: 6 \\n Tutor: Excellent answer! \\n Tuto...</td>\n",
       "      <td>Mistral</td>\n",
       "      <td>It sounds like you're thinking of a \"polygon,\"...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>296362576</td>\n",
       "      <td>Student: 6 \\n Tutor: Excellent answer! \\n Tuto...</td>\n",
       "      <td>Phi3</td>\n",
       "      <td>That's a good try! Actually, the name of the s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>296362576</td>\n",
       "      <td>Student: 6 \\n Tutor: Excellent answer! \\n Tuto...</td>\n",
       "      <td>Sonnet</td>\n",
       "      <td>Great effort! It's actually spelled \"polygon,\"...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>296362576</td>\n",
       "      <td>Student: 6 \\n Tutor: Excellent answer! \\n Tuto...</td>\n",
       "      <td>GPT4</td>\n",
       "      <td>That's a great try, but the correct spelling i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>296362576</td>\n",
       "      <td>Student: 6 \\n Tutor: Excellent answer! \\n Tuto...</td>\n",
       "      <td>Novice</td>\n",
       "      <td>That is a good try.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>1990-60fb8cf6-06e1-4267-80c8-862885d63d9e</td>\n",
       "      <td>Tutor: Hi, could you please provide a step-by-...</td>\n",
       "      <td>Sonnet</td>\n",
       "      <td>I appreciate your reasoning, but let's take a ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>1990-60fb8cf6-06e1-4267-80c8-862885d63d9e</td>\n",
       "      <td>Tutor: Hi, could you please provide a step-by-...</td>\n",
       "      <td>Expert</td>\n",
       "      <td>That's true, but if there are 50 this week, ho...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>1990-60fb8cf6-06e1-4267-80c8-862885d63d9e</td>\n",
       "      <td>Tutor: Hi, could you please provide a step-by-...</td>\n",
       "      <td>Llama31405B</td>\n",
       "      <td>That's a great idea to try to figure out the n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>1990-60fb8cf6-06e1-4267-80c8-862885d63d9e</td>\n",
       "      <td>Tutor: Hi, could you please provide a step-by-...</td>\n",
       "      <td>Llama318B</td>\n",
       "      <td>I see what you're trying to do, but the questi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>1990-60fb8cf6-06e1-4267-80c8-862885d63d9e</td>\n",
       "      <td>Tutor: Hi, could you please provide a step-by-...</td>\n",
       "      <td>GPT4</td>\n",
       "      <td>I understand why you might think that, but the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>409 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               conversation_id  \\\n",
       "0                                    296362576   \n",
       "1                                    296362576   \n",
       "2                                    296362576   \n",
       "3                                    296362576   \n",
       "4                                    296362576   \n",
       "..                                         ...   \n",
       "404  1990-60fb8cf6-06e1-4267-80c8-862885d63d9e   \n",
       "405  1990-60fb8cf6-06e1-4267-80c8-862885d63d9e   \n",
       "406  1990-60fb8cf6-06e1-4267-80c8-862885d63d9e   \n",
       "407  1990-60fb8cf6-06e1-4267-80c8-862885d63d9e   \n",
       "408  1990-60fb8cf6-06e1-4267-80c8-862885d63d9e   \n",
       "\n",
       "                                  conversation_history        tutor  \\\n",
       "0    Student: 6 \\n Tutor: Excellent answer! \\n Tuto...      Mistral   \n",
       "1    Student: 6 \\n Tutor: Excellent answer! \\n Tuto...         Phi3   \n",
       "2    Student: 6 \\n Tutor: Excellent answer! \\n Tuto...       Sonnet   \n",
       "3    Student: 6 \\n Tutor: Excellent answer! \\n Tuto...         GPT4   \n",
       "4    Student: 6 \\n Tutor: Excellent answer! \\n Tuto...       Novice   \n",
       "..                                                 ...          ...   \n",
       "404  Tutor: Hi, could you please provide a step-by-...       Sonnet   \n",
       "405  Tutor: Hi, could you please provide a step-by-...       Expert   \n",
       "406  Tutor: Hi, could you please provide a step-by-...  Llama31405B   \n",
       "407  Tutor: Hi, could you please provide a step-by-...    Llama318B   \n",
       "408  Tutor: Hi, could you please provide a step-by-...         GPT4   \n",
       "\n",
       "                                              response  preds  \n",
       "0    It sounds like you're thinking of a \"polygon,\"...      0  \n",
       "1    That's a good try! Actually, the name of the s...      0  \n",
       "2    Great effort! It's actually spelled \"polygon,\"...      0  \n",
       "3    That's a great try, but the correct spelling i...      0  \n",
       "4                                  That is a good try.      2  \n",
       "..                                                 ...    ...  \n",
       "404  I appreciate your reasoning, but let's take a ...      1  \n",
       "405  That's true, but if there are 50 this week, ho...      1  \n",
       "406  That's a great idea to try to figure out the n...      0  \n",
       "407  I see what you're trying to do, but the questi...      1  \n",
       "408  I understand why you might think that, but the...      1  \n",
       "\n",
       "[409 rows x 5 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84862d26-b931-4031-899d-03aeff53aaf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0474966-3cc4-4550-8f56-02deec81dfa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cb1057-c1bc-4512-89b9-52d18805dcfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8dc52bd5-3ec1-4edc-9edc-9302af65e2d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation</th>\n",
       "      <th>actionability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Student: ok i got the answer \\n Tutor: You hav...</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tutor: Hi, could you please provide a step-by-...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tutor: Hi, could you please provide a step-by-...</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tutor:  Hi, could you please provide a step-by...</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tutor: Consider the first digit in the given n...</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        conversation actionability\n",
       "0  Student: ok i got the answer \\n Tutor: You hav...           Yes\n",
       "1  Tutor: Hi, could you please provide a step-by-...            No\n",
       "2  Tutor: Hi, could you please provide a step-by-...           Yes\n",
       "3  Tutor:  Hi, could you please provide a step-by...           Yes\n",
       "4  Tutor: Consider the first digit in the given n...           Yes"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"test_bea.csv\")\n",
    "test_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812d18ea-adc3-4a8c-baab-9457a1d5adab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "test_data = ConvoData(test_df, tokenizer)\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_data,\n",
    "    batch_size=4,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "true = []\n",
    "preds = []\n",
    "\n",
    "for batch_id, batch in enumerate(test_dataloader):\n",
    "    input_ids = batch[0]['input_ids'].squeeze(dim=1).to(device)\n",
    "    attention_mask = batch[0]['attention_mask'].squeeze(dim=1).to(device)\n",
    "\n",
    "    out = model(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        output_hidden_states=False\n",
    "    )\n",
    "    out = F.log_softmax(out.logits, dim=-1)\n",
    "\n",
    "    true += batch[1].tolist()\n",
    "    preds += out.argmax(dim=-1).tolist()\n",
    "\n",
    "print(sum([i == j for i, j in zip(preds, true)]) / len(test_data))\n",
    "\n",
    "f1 = f1_score(true, preds, average='macro')\n",
    "print(\"F1 score:\", f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
